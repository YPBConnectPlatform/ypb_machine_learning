{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organize directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in training a ML model on sequences of images acquired from the ProtectCode app is to ensure the directory structure is set up for subsequent data loading. \n",
    "\n",
    "These commands assume the following: \n",
    "\n",
    "1) That the top directory for the training data and this notebook are both located in ~/src/YPB-AI/ on the EC2 instance. To get a zipped directory from S3 to that directory on your EC2 instance, you can run the following bash command: \"aws s3 cp s3://your-bucket-name/yourZipFile.zip ~/src/YPB-AI/yourZipFile.zip\". And to unzip it, you can run \"unzip yourZipFile.zip\"\n",
    "\n",
    "2) That the jupyter notebook server was opened from the ~/src/ directory on the EC2 instance via the command \"jupyter notebook --ip=0.0.0.0 --no-browser\".\n",
    "\n",
    "3) That underneath the top directory (which I usually call \"Training\" or something of the like), there are a series of subdirectories named and organized by classification label. For instance, each subdirectory that contains true negative image sequences, according to my implementation, contains the word \"Negative\". And subdirectories with true positives do not contain the word \"Negative\". \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import os, sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the name of your top data directory below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "topDirName = 'Training'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lump together all subdirectories with the same classification label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assumes current working directory is ~/src/YPB-AI\n",
    "allSamples = np.array(glob(topDirName + '/*'))\n",
    "os.system('mkdir ' + topDirName + '/Absent')\n",
    "os.system('mkdir ' + topDirName + '/Present')\n",
    "\n",
    "for sample in allSamples: \n",
    "    if 'Negative' in sample or 'Sat' in sample:\n",
    "        cmdString = \"mv \" + sample + \" \" + topDirName + \"/Absent\"\n",
    "    else:\n",
    "        cmdString = \"mv \" + sample + \" \" + topDirName + \"/Present\"\n",
    "    os.system(cmdString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each directory within the classification subdirectory contains a series of folders that have the following contents:\n",
    "\n",
    "1) A .txt file containing some timing and other metadata about the app run.\n",
    "\n",
    "2) A folder called 'Photos' which contains the sequence of images acquired.\n",
    "\n",
    "The next cell will obliterate the middle directory (the directory just below the classification directory) and repackage each run's photos into a uniquely identifiable folder of its own (lacking the text file) at the level where the middle directories once sat.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find 'vestigial' directories to be deleted after unpacking.\n",
    "presentVestDirs = np.array(glob(topDirName + '/Present/*'))\n",
    "absentVestDirs = np.array(glob(topDirName + '/Absent/*'))\n",
    "\n",
    "# Unpack the JPG photo files into identifiable directories.\n",
    "allPresentSamples = np.array(glob(topDirName + '/Present/*/*'))\n",
    "for sample in allPresentSamples:\n",
    "    # Grab the unique identifiers -- phone model, sample # and date/time\n",
    "    digestedSample = re.split('/',sample)\n",
    "    digestedTimestamp = re.split('_',digestedSample[3])\n",
    "    newDir = digestedSample[2] + '_' + digestedTimestamp[1] + '_' + digestedTimestamp[2]\n",
    "    # Make the new directory\n",
    "    cmdString = 'mkdir ' + topDirName + '/Present/' + newDir\n",
    "    os.system(cmdString)\n",
    "    # Add the photos directly to it\n",
    "    cmdString = 'mv ' + sample + '/Photos/*' + ' ' + topDirName + '/Present/' + newDir\n",
    "    os.system(cmdString)\n",
    "    \n",
    "allAbsentSamples = np.array(glob(topDirName + '/Absent/*/*'))\n",
    "for sample in allAbsentSamples:\n",
    "    # Grab the unique identifiers -- phone model, sample # and date/time\n",
    "    digestedSample = re.split('/',sample)\n",
    "    digestedTimestamp = re.split('_',digestedSample[3])\n",
    "    newDir = digestedSample[2] + '_' + digestedTimestamp[1] + '_' + digestedTimestamp[2]\n",
    "    # Make the new directory\n",
    "    cmdString = 'mkdir ' + topDirName + '/Absent/' + newDir\n",
    "    os.system(cmdString)\n",
    "    # Add the photos directly to it\n",
    "    cmdString = 'mv ' + sample + '/Photos/*' + ' ' + topDirName + '/Absent/' + newDir\n",
    "    os.system(cmdString)\n",
    "    \n",
    "    \n",
    "# Delete vestigial directories.\n",
    "for direc in presentVestDirs:\n",
    "    os.system('rm -rf ' + direc)\n",
    "    \n",
    "for direc in absentVestDirs:\n",
    "    os.system('rm -rf ' + direc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look through all directories and find image sequences containing the file \"IMG_9999.JPG\". If found, sort and rename to an appropriate image sequence. This is necessary because when iOS reaches \"IMG_9999.JPG\" it wraps back around to \"IMG_0000.JPG\" for the next in the sequence. If this is left as is, the sorting operation that follows will sort the images into the incorrect timing order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the filenames.\n",
    "imgSeqsToCorrect = os.popen('cd ~/src/YPB-AI/; find -name \"*IMG_9999.JPG\"').read()\n",
    "# Split into unique entities.\n",
    "imgSeqsToCorrect = re.split('\\n',imgSeqsToCorrect)\n",
    "# Drop the last entry, it's empty.\n",
    "imgSeqsToCorrect.pop();\n",
    "\n",
    "# Change any files that don't start with 'IMG_9' (i.e., any files that come after the wraparound) to start with 'J'.\n",
    "# This will mean that when they are sorted, they will come correctly after the wraparound.\n",
    "for sample in imgSeqsToCorrect:\n",
    "    digestedSample = re.split('/',sample)\n",
    "    pathToDir = os.path.join(digestedSample[0],digestedSample[1],digestedSample[2],digestedSample[3])\n",
    "    filesInDir = os.listdir(pathToDir)\n",
    "    for i in range(len(filesInDir)):\n",
    "        if 'IMG_9' not in filesInDir[i]:\n",
    "            newFile = filesInDir[i].replace('I','J',1)\n",
    "            cmdString = 'mv ' + os.path.join(pathToDir,filesInDir[i]) + ' ' + os.path.join(pathToDir,newFile)\n",
    "            os.system(cmdString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use a CNN to transform image sequences to a pickle file and organize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a pretrained CNN model (here using DenseNet121 because it has worked well in the past) with the final classifier layer chopped off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the CNN model and move it to CUDA if available.\n",
    "model = models.densenet121(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "del model.classifier\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.to('cuda');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the function that will transform model output into a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_pickle(model,topdir):\n",
    "    model.eval()\n",
    "    ndx = 0\n",
    "    topdirs = [direc for direc in os.listdir(topdir) if direc[0] is not '.']\n",
    "    \n",
    "    # Calculate the total number of stacks to transform.\n",
    "    numStacks = 0\n",
    "    for classDir in topdirs:\n",
    "        thisClassDir = os.path.join(topdir,classDir)\n",
    "        directories = [direc for direc in os.listdir(thisClassDir) if direc[0] is not '.']\n",
    "        numStacks += len(directories)\n",
    "    \n",
    "    for classDir in topdirs:\n",
    "        thisClassDir = os.path.join(topdir,classDir)\n",
    "        directories = [direc for direc in os.listdir(thisClassDir) if direc[0] is not '.']\n",
    "        \n",
    "        \n",
    "        # Do the transformation.\n",
    "        for photoDir in directories:\n",
    "            \n",
    "            thisPhotoDir = os.path.join(thisClassDir, photoDir)\n",
    "            ##pin pin fix##\n",
    "            \n",
    "#             print(thisPhotoDir)\n",
    "#             print(os.path.isfile(photoDir))\n",
    "#             continue\n",
    "            \n",
    "            if not os.path.isdir(thisPhotoDir):\n",
    "                continue\n",
    "\n",
    "            ## end ##\n",
    "            files = [photofile for photofile in os.listdir(thisPhotoDir) if photofile.lower().endswith('jpg')]\n",
    "            print(\"Transforming image stack {}\".format(thisPhotoDir))\n",
    "            files.sort()\n",
    "            output = []\n",
    "            # Make sure to appropriately transform the image size and normalize the RGB values, as the model expects. \n",
    "            for file in files:\n",
    "                thisFile = os.path.join(thisPhotoDir,file)\n",
    "                imgArr = np.float32(np.array(Image.open(thisFile).resize((224,224))).reshape([1,3,224,224]))\n",
    "                imgArr[0][0] = ((imgArr[0][0] - 123.675)/58.395)\n",
    "                imgArr[0][1] = ((imgArr[0][1] - 116.28)/57.12)\n",
    "                imgArr[0][2] = ((imgArr[0][2] - 103.53)/57.375)\n",
    "                if torch.cuda.is_available():\n",
    "                    output.append(model(torch.cuda.FloatTensor(imgArr)))\n",
    "                else:\n",
    "                    output.append(model(torch.FloatTensor(imgArr)))\n",
    "\n",
    "            FinalOutput = torch.FloatTensor(len(files),1,1024)\n",
    "            for i in range(len(files)):\n",
    "                FinalOutput[i] = output[i]\n",
    "            pathStr = thisPhotoDir + '.pickle'\n",
    "            with open(pathStr,'wb') as f:\n",
    "                pickle.dump(FinalOutput,f)\n",
    "                ndx += 1\n",
    "                print(\"{}% complete.\".format(ndx/numStacks*100))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: 'Training/Absent/XS_Negative_Dark_14-Mar-2019_17-13-38.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-f0bb9e94c386>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransform_to_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtopDirName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-6333eb4ccc74>\u001b[0m in \u001b[0;36mtransform_to_pickle\u001b[0;34m(model, topdir)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mthisPhotoDir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthisClassDir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphotoDir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mphotofile\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mphotofile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthisPhotoDir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mphotofile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Transforming image stack {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthisPhotoDir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: 'Training/Absent/XS_Negative_Dark_14-Mar-2019_17-13-38.pickle'"
     ]
    }
   ],
   "source": [
    "transform_to_pickle(model,topDirName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up the directory, removing everything but the pickle files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble all the pickle files and remove the rest.\n",
    "classDirs = [direc for direc in os.listdir(topDirName) if direc[0] is not '.']\n",
    "for classDir in classDirs:\n",
    "    newDir = os.path.join(topDirName,classDir)\n",
    "    fileDirs = [direc for direc in os.listdir(newDir) if direc[0] is not '.' and not direc.lower().endswith('.pickle')]\n",
    "    for fileDir in fileDirs:\n",
    "        pickleFileDir = os.path.join(newDir,fileDir)\n",
    "        os.system('rm -rf ' + pickleFileDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the directory into train/test/validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDirName = 'Split_Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_folders(inputDir, outputDir, trainValTestRatio, seed):\n",
    "    # Assume inputDir is organized as 'inputDir/class/topFolder/photos'\n",
    "    classes = os.listdir(inputDir)\n",
    "    # Exclude folders where '.' is the first character.\n",
    "    classes = [directory for directory in classes if directory[0] != '.']\n",
    "    numClasses = len(classes)\n",
    "    # Create output directories\n",
    "    os.system('mkdir ' + outputDir)\n",
    "    os.system('mkdir ' + outputDir + '/train')\n",
    "    os.system('mkdir ' + outputDir + '/valid')\n",
    "    os.system('mkdir ' + outputDir + '/test')\n",
    "    # Pull files and put into the appropriate folders.\n",
    "    for directory in classes:\n",
    "        files = os.listdir(os.path.join(inputDir, directory))\n",
    "        files.sort()\n",
    "        random.seed(seed)\n",
    "        random.shuffle(files)\n",
    "        numFiles = len(files)\n",
    "        # Get the indices.\n",
    "        ndxAmts = np.intc((np.round(trainValTestRatio / np.sum(trainValTestRatio) * numFiles)))\n",
    "        numNdxes = np.sum(ndxAmts)\n",
    "        if numNdxes != numFiles:\n",
    "            ndxAmts[0] += numFiles-numNdxes\n",
    "        trainFiles = files[0:ndxAmts[0]]\n",
    "        valFiles = files[ndxAmts[0]:ndxAmts[0]+ndxAmts[1]]\n",
    "        testFiles = files[ndxAmts[0]+ndxAmts[1]:]\n",
    "        # Put the training directories in the appropriate folder\n",
    "        # First make the class directories.\n",
    "        os.system('mkdir ' + outputDir + '/train/' + directory)\n",
    "        os.system('mkdir ' + outputDir + '/valid/' + directory)\n",
    "        os.system('mkdir ' + outputDir + '/test/' + directory)\n",
    "        for file in trainFiles:\n",
    "            os.system('cp -r ' + inputDir + '/' + directory + '/' + file + ' ' + outputDir + '/train/' + directory + '/' + file)\n",
    "        for file in valFiles:\n",
    "            os.system('cp -r ' + inputDir + '/' + directory + '/' + file + ' ' + outputDir + '/valid/' + directory + '/' + file)\n",
    "        for file in testFiles:\n",
    "            os.system('cp -r ' + inputDir + '/' + directory + '/' + file + ' ' + outputDir + '/test/' + directory + '/' + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_folders(topDirName, finalDirName,[0.8,0.1,0.1],7778)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_derm-ai)",
   "language": "python",
   "name": "conda_derm-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
