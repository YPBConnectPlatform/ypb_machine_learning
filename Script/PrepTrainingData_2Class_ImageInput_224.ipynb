{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import os, sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "topDirName = '/home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assumes current working directory is ~/src/YPB-AI\n",
    "allSamples = np.array(glob(topDirName + '/*'))\n",
    "os.system('mkdir ' + topDirName + '/Absent')\n",
    "os.system('mkdir ' + topDirName + '/Present')\n",
    "\n",
    "for sample in allSamples: \n",
    "    if 'Negative' in sample or 'Sat' in sample:\n",
    "        cmdString = \"mv \" + sample + \" \" + topDirName + \"/Absent\"\n",
    "    else:\n",
    "        cmdString = \"mv \" + sample + \" \" + topDirName + \"/Present\"\n",
    "    os.system(cmdString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'home',\n",
       " 'ubuntu',\n",
       " 'src',\n",
       " 'YPB-AI',\n",
       " 'beforeSplit',\n",
       " 'AlexNet',\n",
       " 'Training',\n",
       " 'Present',\n",
       " '6_Sample2_Dark',\n",
       " 'ProtectCodeScannerResults_08-Mar-2019_17-15-26']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digestedSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find 'vestigial' directories to be deleted after unpacking.\n",
    "presentVestDirs = np.array(glob(topDirName + '/Present/*'))\n",
    "absentVestDirs = np.array(glob(topDirName + '/Absent/*'))\n",
    "\n",
    "# Unpack the JPG photo files into identifiable directories.\n",
    "allPresentSamples = np.array(glob(topDirName + '/Present/*/*'))\n",
    "for sample in allPresentSamples:\n",
    "    # Grab the unique identifiers -- phone model, sample # and date/time\n",
    "    digestedSample = re.split('/',sample)\n",
    "    digestedTimestamp = re.split('_',digestedSample[10])\n",
    "    newDir = digestedSample[9] + '_' + digestedTimestamp[1] + '_' + digestedTimestamp[2]\n",
    "    # Make the new directory\n",
    "    cmdString = 'mkdir ' + topDirName + '/Present/' + newDir\n",
    "    os.system(cmdString)\n",
    "    # Add the photos directly to it\n",
    "    cmdString = 'mv ' + sample + '/Photos/*' + ' ' + topDirName + '/Present/' + newDir\n",
    "    os.system(cmdString)\n",
    "    \n",
    "allAbsentSamples = np.array(glob(topDirName + '/Absent/*/*'))\n",
    "for sample in allAbsentSamples:\n",
    "    # Grab the unique identifiers -- phone model, sample # and date/time\n",
    "    digestedSample = re.split('/',sample)\n",
    "    digestedTimestamp = re.split('_',digestedSample[10])\n",
    "    newDir = digestedSample[9] + '_' + digestedTimestamp[1] + '_' + digestedTimestamp[2]\n",
    "    # Make the new directory\n",
    "    cmdString = 'mkdir ' + topDirName + '/Absent/' + newDir\n",
    "    os.system(cmdString)\n",
    "    # Add the photos directly to it\n",
    "    cmdString = 'mv ' + sample + '/Photos/*' + ' ' + topDirName + '/Absent/' + newDir\n",
    "    os.system(cmdString)\n",
    "    \n",
    "    \n",
    "# Delete vestigial directories.\n",
    "for direc in presentVestDirs:\n",
    "    os.system('rm -rf ' + direc)\n",
    "    \n",
    "for direc in absentVestDirs:\n",
    "    os.system('rm -rf ' + direc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the filenames.\n",
    "# imgSeqsToCorrect = os.popen('cd ~/src/YPB-AI/; find -name \"*IMG_9999.JPG\"').read()\n",
    "imgSeqsToCorrect = os.popen('cd ~/src/YPB-AI/beforeSplit/AlexNet/Training/; find -name \"*IMG_9999.JPG\"').read()\n",
    "# Split into unique entities.\n",
    "imgSeqsToCorrect = re.split('\\n',imgSeqsToCorrect)\n",
    "# Drop the last entry, it's empty.\n",
    "imgSeqsToCorrect.pop();\n",
    "\n",
    "# Change any files that don't start with 'IMG_9' (i.e., any files that come after the wraparound) to start with 'J'.\n",
    "# This will mean that when they are sorted, they will come correctly after the wraparound.\n",
    "for sample in imgSeqsToCorrect:\n",
    "    digestedSample = re.split('/',sample)\n",
    "    # pathToDir = os.path.join(digestedSample[0],digestedSample[1],digestedSample[2],digestedSample[3])\n",
    "    pathToDir = os.path.join(topDirName,digestedSample[1],digestedSample[2])\n",
    "    # pathToDir = topDirName + '/' + digestedSample[0] + '/' + digestedSample[1] + '/' + digestedSample[2] + '/' + digestedSample[3]\n",
    "    # try:\n",
    "    filesInDir = os.listdir(pathToDir)\n",
    "    for i in range(len(filesInDir)):\n",
    "        if 'IMG_9' not in filesInDir[i]:\n",
    "            newFile = filesInDir[i].replace('I','J',1)\n",
    "            # cmdString = 'mv ' + os.path.join(pathToDir,filesInDir[i]) + ' ' + os.path.join(pathToDir,newFile)\n",
    "            cmdString = 'mv ' + os.path.join(pathToDir,filesInDir[i]) + ' ' + os.path.join(pathToDir,newFile)\n",
    "            # cmdString = 'mv ' + '/' + filesInDir[i] + '/' + ' ' + pathToDir + '/' + newFile\n",
    "            # print(cmdString)\n",
    "            os.system(cmdString)\n",
    "    # except Exception as e:\n",
    "    #     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.', 'Absent', '6S_Negative_Dark_14-Mar-2019_09-53-30', 'IMG_9999.JPG']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digestedSample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use AlexNet to transform image sequences to a pickle file and organize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the CNN model (AlexNet) and move it to CUDA if available.\n",
    "model = models.alexnet(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "del model.classifier\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.to('cuda');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/6S_Negative_Sample3_Light_16-Apr-2019_15-59-47\n",
      "0.008768084173608068% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/XS_Sat2_07-Jun-2019_20-13-37\n",
      "0.017536168347216136% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/6_Negative_Sample3_Back_Light_16-Apr-2019_13-17-37\n",
      "0.026304252520824196% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/SE_Negative_Dark_15-Mar-2019_15-37-50\n",
      "0.03507233669443227% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/XS_Sat_17-Apr-2019_11-36-09\n",
      "0.04384042086804033% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/6_Negative_Sample3_Back_Light_16-Apr-2019_14-11-36\n",
      "0.05260850504164839% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/6_Negative_Dark_13-Mar-2019_13-01-20\n",
      "0.06137658921525647% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/XS_Sat2_07-Jun-2019_16-46-00\n",
      "0.07014467338886454% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/7_Negative_Dark_13-Mar-2019_16-21-25\n",
      "0.0789127575624726% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/7_Negative_Dark_13-Mar-2019_17-56-35\n",
      "0.08768084173608066% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/7_Negative_Dark_13-Mar-2019_16-47-38\n",
      "0.09644892590968873% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/XS_Sat2_07-Jun-2019_18-10-40\n",
      "0.10521701008329679% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/6_Negative_Sample3_Back_Light_16-Apr-2019_12-57-41\n",
      "0.11398509425690487% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/XS_Negative_Random_04-Jun-2019_10-04-00\n",
      "0.12275317843051294% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/7_Negative_Random_30-May-2019_16-39-26\n",
      "0.131521262604121% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/XS_Sat2_07-Jun-2019_17-59-01\n",
      "0.14028934677772908% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/6_Negative_Dark_13-Mar-2019_10-31-20\n",
      "0.1490574309513371% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/7_Negative_Dark_13-Mar-2019_17-37-27\n",
      "0.1578255151249452% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/6S_Negative_Dark_14-Mar-2019_10-51-55\n",
      "0.16659359929855327% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/SE_Negative_Dark_15-Mar-2019_15-49-24\n",
      "0.17536168347216133% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/XS_Negative_Random_04-Jun-2019_10-12-55\n",
      "0.1841297676457694% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/XS_Sat2_07-Jun-2019_19-52-58\n",
      "0.19289785181937746% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/7_Negative_Dark_13-Mar-2019_17-27-13\n",
      "0.20166593599298555% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/6S_Negative_Dark_14-Mar-2019_10-55-43\n",
      "0.21043402016659357% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/7_Negative_Dark_13-Mar-2019_18-08-14\n",
      "0.21920210434020165% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/6S_Negative_Dark_14-Mar-2019_09-44-45\n",
      "0.22797018851380974% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/XS_Negative_Random_04-Jun-2019_10-38-20\n",
      "0.2367382726874178% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/7_Negative_Random_30-May-2019_16-32-42\n",
      "0.24550635686102587% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/6_Negative_Sample3_Back_Light_16-Apr-2019_12-52-14\n",
      "0.2542744410346339% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/6S_Negative_Random_03-Jun-2019_14-42-38\n",
      "0.263042525208242% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/XS_Negative_Sample3_Light_17-Apr-2019_11-54-52\n",
      "0.2718106093818501% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/XS_Sat2_07-Jun-2019_20-14-25\n",
      "0.28057869355545817% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/XS_Sat_07-Jun-2019_14-14-40\n",
      "0.2893467777290662% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/7_Negative_Sample3_Light_16-Apr-2019_17-57-00\n",
      "0.2981148619026742% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/SE_Negative_Random_03-Jun-2019_16-31-36\n",
      "0.3068829460762823% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/XS_Sat2_07-Jun-2019_17-35-32\n",
      "0.3156510302498904% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/6_Negative_Dark_13-Mar-2019_11-02-51\n",
      "0.32441911442349847% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/XS_Negative_Random_30-May-2019_15-25-20\n",
      "0.33318719859710655% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/XS_Sat2_07-Jun-2019_18-29-10\n",
      "0.34195528277071463% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/6_Negative_Dark_13-Mar-2019_12-27-43\n",
      "0.35072336694432266% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/6_Negative_Dark_13-Mar-2019_12-04-50\n",
      "0.35949145111793074% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/XS_Negative_Random_30-May-2019_15-40-05\n",
      "0.3682595352915388% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/SE_Negative_Random_03-Jun-2019_16-34-06\n",
      "0.37702761946514685% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/XS_Negative_Dark_14-Mar-2019_17-28-15\n",
      "0.3857957036387549% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/SE_Negative_Dark_15-Mar-2019_15-31-49\n",
      "0.394563787812363% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/6S_Negative_Sample3_Light_16-Apr-2019_15-41-48\n",
      "0.4033318719859711% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/6S_Sat_03-Jun-2019_15-27-04\n",
      "0.41209995615957906% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/6_Negative_Sample3_Back_Light_16-Apr-2019_14-12-28\n",
      "0.42086804033318714% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/XS_Negative_Random_04-Jun-2019_09-59-51\n",
      "0.4296361245067952% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/XS_Sat2_07-Jun-2019_20-50-14\n",
      "0.4384042086804033% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/XS_Sat2_07-Jun-2019_16-44-20\n",
      "0.4471722928540114% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/XS_Sat_07-Jun-2019_14-32-51\n",
      "0.45594037702761947% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/XS_Sat2_07-Jun-2019_18-07-03\n",
      "0.4647084612012275% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/6_Negative_Dark_13-Mar-2019_11-42-50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4734765453748356% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/XS_Sat2_07-Jun-2019_17-28-05\n",
      "0.48224462954844366% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/XS_Sat_17-Apr-2019_11-36-24\n",
      "0.49101271372205174% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/SE_Negative_Dark_15-Mar-2019_16-40-40\n",
      "0.4997807978956598% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/7_Negative_Dark_13-Mar-2019_16-51-57\n",
      "0.5085488820692678% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/6S_Sat_03-Jun-2019_14-19-25\n",
      "0.5173169662428759% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/XS_Sat2_07-Jun-2019_18-38-34\n",
      "0.526085050416484% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/7_Negative_Sample3_Light_16-Apr-2019_18-20-59\n",
      "0.5348531345900921% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/XS_Negative_Random_30-May-2019_14-32-57\n",
      "0.5436212187637002% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/7_Negative_Dark_13-Mar-2019_17-49-17\n",
      "0.5523893029373083% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/7_Negative_Dark_13-Mar-2019_15-43-48\n",
      "0.5611573871109163% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/6_Negative_Sample3_Back_Light_16-Apr-2019_14-35-57\n",
      "0.5699254712845244% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/XS_Sat_07-Jun-2019_14-27-08\n",
      "0.5786935554581324% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/7_Negative_Sample3_Light_16-Apr-2019_17-51-45\n",
      "0.5874616396317405% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/6_Negative_Dark_13-Mar-2019_14-01-40\n",
      "0.5962297238053484% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/6S_Negative_Sample3_Light_16-Apr-2019_16-33-35\n",
      "0.6049978079789565% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/7_Negative_Dark_13-Mar-2019_16-36-47\n",
      "0.6137658921525646% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/6S_Negative_Dark_14-Mar-2019_11-34-07\n",
      "0.6225339763261727% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/6_Negative_Dark_13-Mar-2019_10-27-49\n",
      "0.6313020604997808% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/XS_Negative_Random_04-Jun-2019_10-38-08\n",
      "0.6400701446733889% complete.\n",
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/6S_Negative_Sample3_Light_16-Apr-2019_15-34-25\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-7c9406a63907>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mthisFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthisPhotoDir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mimgArr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthisFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mimgArr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgArr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m123.675\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m58.395\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mimgArr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgArr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m116.28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m57.12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/derm-ai/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box)\u001b[0m\n\u001b[1;32m   1761\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGBa'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGBA'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1763\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1765\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/derm-ai/lib/python3.6/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# This part is for converting into image. Not using it now.\n",
    "# topdir = topDirName\n",
    "# ndx = 0\n",
    "# topdirs = [direc for direc in os.listdir(topdir) if direc[0] is not '.']\n",
    "\n",
    "# # Calculate the total number of stacks to transform.\n",
    "# numStacks = 0\n",
    "# for classDir in topdirs:\n",
    "#     thisClassDir = os.path.join(topdir,classDir)\n",
    "#     directories = [direc for direc in os.listdir(thisClassDir) if direc[0] is not '.']\n",
    "#     numStacks += len(directories)\n",
    "\n",
    "# for classDir in topdirs:\n",
    "#     thisClassDir = os.path.join(topdir,classDir)\n",
    "#     directories = [direc for direc in os.listdir(thisClassDir) if direc[0] is not '.']\n",
    "\n",
    "\n",
    "#     # Do the transformation.\n",
    "#     for photoDir in directories:\n",
    "\n",
    "#         thisPhotoDir = os.path.join(thisClassDir, photoDir)\n",
    "#         ##pin pin fix##\n",
    "\n",
    "# #             print(thisPhotoDir)\n",
    "# #             print(os.path.isfile(photoDir))\n",
    "# #             continue\n",
    "\n",
    "#         if not os.path.isdir(thisPhotoDir):\n",
    "#             continue\n",
    "\n",
    "#         ## end ##\n",
    "#         files = [photofile for photofile in os.listdir(thisPhotoDir) if photofile.lower().endswith('jpg')]\n",
    "#         print(\"Transforming image stack {}\".format(thisPhotoDir))\n",
    "#         files.sort()\n",
    "#         output = []\n",
    "#         # Make sure to appropriately transform the image size and normalize the RGB values, as the model expects. \n",
    "#         for file in files:\n",
    "#             thisFile = os.path.join(thisPhotoDir,file)\n",
    "#             imgArr = np.float32(np.array(Image.open(thisFile).resize((224,224))).reshape([1,3,224,224]))\n",
    "#             imgArr[0][0] = ((imgArr[0][0] - 123.675)/58.395)\n",
    "#             imgArr[0][1] = ((imgArr[0][1] - 116.28)/57.12)\n",
    "#             imgArr[0][2] = ((imgArr[0][2] - 103.53)/57.375)\n",
    "#             output.append(imgArr)\n",
    "\n",
    "#         FinalOutput = torch.FloatTensor(output)\n",
    "#         # for i in range(len(files)):\n",
    "#         #    FinalOutput[i] = output[i]\n",
    "#         pathStr = thisPhotoDir + '.pickle'\n",
    "#         with open(pathStr,'wb') as f:\n",
    "#             pickle.dump(FinalOutput,f)\n",
    "#             ndx += 1\n",
    "#             print(\"{}% complete.\".format(ndx/numStacks*100))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the function that will transform model output into a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_pickle(model,topdir):\n",
    "    model.eval()\n",
    "    ndx = 0\n",
    "    topdirs = [direc for direc in os.listdir(topdir) if direc[0] is not '.']\n",
    "    \n",
    "    # Calculate the total number of stacks to transform.\n",
    "    numStacks = 0\n",
    "    for classDir in topdirs:\n",
    "        thisClassDir = os.path.join(topdir,classDir)\n",
    "        directories = [direc for direc in os.listdir(thisClassDir) if direc[0] is not '.']\n",
    "        numStacks += len(directories)\n",
    "    \n",
    "    for classDir in topdirs:\n",
    "        thisClassDir = os.path.join(topdir,classDir)\n",
    "        directories = [direc for direc in os.listdir(thisClassDir) if direc[0] is not '.']\n",
    "        \n",
    "        \n",
    "        # Do the transformation.\n",
    "        for photoDir in directories:\n",
    "            \n",
    "            thisPhotoDir = os.path.join(thisClassDir, photoDir)\n",
    "            ##pin pin fix##\n",
    "            \n",
    "#             print(thisPhotoDir)\n",
    "#             print(os.path.isfile(photoDir))\n",
    "#             continue\n",
    "            \n",
    "            if not os.path.isdir(thisPhotoDir):\n",
    "                continue\n",
    "\n",
    "            ## end ##\n",
    "            files = [photofile for photofile in os.listdir(thisPhotoDir) if photofile.lower().endswith('jpg')]\n",
    "            print(\"Transforming image stack {}\".format(thisPhotoDir))\n",
    "            files.sort()\n",
    "            output = []\n",
    "            # Make sure to appropriately transform the image size and normalize the RGB values, as the model expects. \n",
    "            for file in files:\n",
    "                thisFile = os.path.join(thisPhotoDir,file)\n",
    "                imgArr = np.float32(np.array(Image.open(thisFile).resize((256,256))).reshape([1,3,256,256]))\n",
    "                imgArr[0][0] = ((imgArr[0][0] - 123.675)/58.395)\n",
    "                imgArr[0][1] = ((imgArr[0][1] - 116.28)/57.12)\n",
    "                imgArr[0][2] = ((imgArr[0][2] - 103.53)/57.375)\n",
    "                if torch.cuda.is_available():\n",
    "                    output.append(model(torch.cuda.FloatTensor(imgArr)))\n",
    "                else:\n",
    "                    output.append(model(torch.FloatTensor(imgArr)))\n",
    "\n",
    "            FinalOutput = imgArr\n",
    "            pathStr = thisPhotoDir + '.pickle'\n",
    "            with open(pathStr,'wb') as f:\n",
    "                pickle.dump(FinalOutput,f)\n",
    "                ndx += 1\n",
    "                print(\"{}% complete.\".format(ndx/numStacks*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch pre-trained AlexNet somehow didn't work\n",
    "import torch.nn as nn\n",
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming image stack /home/ubuntu/src/YPB-AI/beforeSplit/AlexNet/Training/Absent/6S_Negative_Sample3_Light_16-Apr-2019_15-59-47\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AlexNet' object has no attribute 'classifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f0bb9e94c386>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransform_to_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtopDirName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-87204dfdc4a8>\u001b[0m in \u001b[0;36mtransform_to_pickle\u001b[0;34m(model, topdir)\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0mimgArr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgArr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m103.53\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m57.375\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                     \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgArr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgArr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/derm-ai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/derm-ai/lib/python3.6/site-packages/torchvision/models/alexnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m6\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/derm-ai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    533\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 535\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AlexNet' object has no attribute 'classifier'"
     ]
    }
   ],
   "source": [
    "transform_to_pickle(model,topDirName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up the directory, removing everything but the pickle files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble all the pickle files and remove the rest.\n",
    "classDirs = [direc for direc in os.listdir(topDirName) if direc[0] is not '.']\n",
    "for classDir in classDirs:\n",
    "    newDir = os.path.join(topDirName,classDir)\n",
    "    fileDirs = [direc for direc in os.listdir(newDir) if direc[0] is not '.' and not direc.lower().endswith('.pickle')]\n",
    "    for fileDir in fileDirs:\n",
    "        pickleFileDir = os.path.join(newDir,fileDir)\n",
    "        os.system('rm -rf ' + pickleFileDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the directory into train/test/validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_folders(inputDir, outputDir, trainValTestRatio, seed):\n",
    "    # Assume inputDir is organized as 'inputDir/class/topFolder/photos'\n",
    "    classes = os.listdir(inputDir)\n",
    "    # Exclude folders where '.' is the first character.\n",
    "    classes = [directory for directory in classes if directory[0] != '.']\n",
    "    numClasses = len(classes)\n",
    "    # Create output directories\n",
    "    os.system('mkdir ' + outputDir)\n",
    "    os.system('mkdir ' + outputDir + '/train')\n",
    "    os.system('mkdir ' + outputDir + '/valid')\n",
    "    os.system('mkdir ' + outputDir + '/test')\n",
    "    # Pull files and put into the appropriate folders.\n",
    "    for directory in classes:\n",
    "        files = os.listdir(os.path.join(inputDir, directory))\n",
    "        files.sort()\n",
    "        random.seed(seed)\n",
    "        random.shuffle(files)\n",
    "        numFiles = len(files)\n",
    "        # Get the indices.\n",
    "        ndxAmts = np.intc((np.round(trainValTestRatio / np.sum(trainValTestRatio) * numFiles)))\n",
    "        numNdxes = np.sum(ndxAmts)\n",
    "        if numNdxes != numFiles:\n",
    "            ndxAmts[0] += numFiles-numNdxes\n",
    "        trainFiles = files[0:ndxAmts[0]]\n",
    "        valFiles = files[ndxAmts[0]:ndxAmts[0]+ndxAmts[1]]\n",
    "        testFiles = files[ndxAmts[0]+ndxAmts[1]:]\n",
    "        # Put the training directories in the appropriate folder\n",
    "        # First make the class directories.\n",
    "        os.system('mkdir ' + outputDir + '/train/' + directory)\n",
    "        os.system('mkdir ' + outputDir + '/valid/' + directory)\n",
    "        os.system('mkdir ' + outputDir + '/test/' + directory)\n",
    "        for file in trainFiles:\n",
    "            os.system('cp -r ' + inputDir + '/' + directory + '/' + file + ' ' + outputDir + '/train/' + directory + '/' + file)\n",
    "        for file in valFiles:\n",
    "            os.system('cp -r ' + inputDir + '/' + directory + '/' + file + ' ' + outputDir + '/valid/' + directory + '/' + file)\n",
    "        for file in testFiles:\n",
    "            os.system('cp -r ' + inputDir + '/' + directory + '/' + file + ' ' + outputDir + '/test/' + directory + '/' + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDirName = 'Split_Data2_29_02_20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Split_Data2_17_01_20'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for idx in range(5):\n",
    "#     split_folders(topDirName, finalDirName_root + str(idx),[0.8,0.1,0.1],1000 + idx)\n",
    "finalDirName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_folders(topDirName, finalDirName,[0.8,0.1,0.1],7778)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_derm-ai)",
   "language": "python",
   "name": "conda_derm-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
