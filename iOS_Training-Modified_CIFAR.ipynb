{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import torch\n",
    "import os, sys, time, csv\n",
    "import re\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import ipywidgets as ipyw\n",
    "import inspect\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process image stacks into feature vector matrices using pre-trained model (for LSTM input)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch imports.\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models.resnet\n",
    "\n",
    "# Visualization imports\n",
    "from IPython import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part A: Load in model pre-trained on individual images. Note that pre-training may not even be necessary, as I was only\n",
    "# changing the weights on the last (new) fully connected layer, and that layer will likely be gotten rid of. \n",
    "model = models.densenet121(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "del model.classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble image pathnames and understand class breakdown in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9123 training stacks, 1141 validation stacks and 1141 test stacks.\n",
      "For the training stacks, 50.1% (4574) are positive and 49.9% (4549) are negative.\n",
      "For the validation stacks, 50.1% (572) are positive and 49.9% (569) are negative.\n",
      "For the test stacks, 50.1% (572) are positive and 49.9% (569) are negative.\n"
     ]
    }
   ],
   "source": [
    "# Note down train, validation and test directories.\n",
    "topDir = 'Split_Data2'\n",
    "\n",
    "train_dir = topDir + \"/train\"\n",
    "valid_dir = topDir + \"/valid\"\n",
    "test_dir = topDir + \"/test\"\n",
    "\n",
    "# Check quantities of train, validation and test images\n",
    "train_images = np.array(glob(train_dir + \"/*/*\"))\n",
    "valid_images = np.array(glob(valid_dir + \"/*/*\"))\n",
    "test_images = np.array(glob(test_dir + \"/*/*\"))\n",
    "\n",
    "# Check relative percentages of image types\n",
    "train_images_absent = np.array(glob(train_dir + \"/Absent/*\"))\n",
    "train_images_present = np.array(glob(train_dir + \"/Present/*\"))\n",
    "\n",
    "valid_images_absent = np.array(glob(valid_dir + \"/Absent/*\"))\n",
    "valid_images_present = np.array(glob(valid_dir + \"/Present/*\"))\n",
    "\n",
    "test_images_absent = np.array(glob(test_dir + \"/Absent/*\"))\n",
    "test_images_present = np.array(glob(test_dir + \"/Present/*\"))\n",
    "\n",
    "num_train_images = len(train_images)\n",
    "num_valid_images = len(valid_images)\n",
    "num_test_images = len(test_images)\n",
    "\n",
    "print(\"There are {} training stacks, {} validation stacks and {} test stacks.\".format(len(train_images),len(valid_images),len(test_images)))\n",
    "print(\"For the training stacks, {pos:=.1f}% ({pos2}) are positive and {neg:=.1f}% ({neg2}) are negative.\".format(pos=len(train_images_present)/len(train_images)*100, pos2=len(train_images_present),neg=len(train_images_absent)/len(train_images)*100, neg2=len(train_images_absent)))\n",
    "print(\"For the validation stacks, {pos:=.1f}% ({pos2}) are positive and {neg:=.1f}% ({neg2}) are negative.\".format(pos=len(valid_images_present)/len(valid_images)*100, pos2=len(valid_images_present),neg=len(valid_images_absent)/len(valid_images)*100, neg2=len(valid_images_absent)))\n",
    "print(\"For the test stacks, {pos:=.1f}% ({pos2}) are positive and {neg:=.1f}% ({neg2}) are negative.\".format(pos=len(test_images_present)/len(test_images)*100, pos2=len(test_images_present),neg=len(test_images_absent)/len(test_images)*100, neg2=len(test_images_absent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for GPU support\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 GPUs found.\n"
     ]
    }
   ],
   "source": [
    "# Check to see how many GPUs are available.\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "if use_cuda:\n",
    "    num_devices = torch.cuda.device_count()\n",
    "    print(\"{} GPUs found.\".format(num_devices))\n",
    "else:\n",
    "    num_devices = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports for torch and DALI functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(224, 224, 3)\n",
    "#         self.conv2 = nn.Conv2d(224, 224, 64) #2 layers\n",
    "#         # http://web.media.mit.edu/~pratiks/combined-classification/convolutional-neural-network-for-combined-classification-of-fluorescent-biomarkers-and-expert-annotations-using-white-light-images.pdf\n",
    "#         # https://www.pyimagesearch.com/2017/03/20/imagenet-vggnet-resnet-inception-xception-keras/\n",
    "#         self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "#         self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "#         self.fc2 = nn.Linear(120, 84)\n",
    "#         self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(F.relu(self.conv1(x)))\n",
    "#         x = self.pool(F.relu(self.conv2(x)))\n",
    "#         x = x.view(-1, 16 * 5 * 5)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "# net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class MM_DNN(nn.Module):\n",
    "    def __init__(self, drop_prob=0.2, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.lr = lr\n",
    "        \n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        self.fc = nn.Linear(4*1024,256)\n",
    "        self.fc2 = nn.Linear(256,64)\n",
    "        self.fc3 = nn.Linear(64,2)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ''' Forward pass through the network. \n",
    "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
    "        x = x.view(-1)\n",
    "        out = self.dropout(self.relu(self.fc(x)))\n",
    "        out = self.dropout(self.relu(self.fc2(out)))\n",
    "        out = self.fc3(out)\n",
    "        # return the final output\n",
    "        return out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the PyTorch data loader here, way easier. \n",
    "def load_pickle(path):\n",
    "    with open(path,'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "train_data = datasets.DatasetFolder(train_dir,load_pickle,'.pickle')\n",
    "validation_data = datasets.DatasetFolder(valid_dir,load_pickle,'.pickle')\n",
    "test_data = datasets.DatasetFolder(test_dir,load_pickle,'.pickle')\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = 1, shuffle=True, drop_last=True, num_workers=num_devices*4, pin_memory=True)\n",
    "valid_loader = torch.utils.data.DataLoader(validation_data, batch_size = 1, num_workers=num_devices*4, pin_memory=True, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = 1, num_workers=num_devices*4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 1, 3, 32, 32])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = load_pickle('/home/ubuntu/src/YPB-AI/Split_Data2/valid/Absent/XS_Negative_Dark_14-Mar-2019_18-53-16.pickle')\n",
    "x.shape\n",
    "# image, label = iter(train_loader).next()\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 32, 32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    # img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()[0]\n",
    "    print(npimg.shape)\n",
    "    plt.imshow(np.transpose(npimg,(1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "# print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveName = 'Testing_CIFAR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_loader, epochs=10, batch_size=2, lr=0.001, print_every=10):\n",
    "    ''' Training a network \n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        \n",
    "        net: DNN network\n",
    "        train_loader: PyTorch dataloader containing data to train the network\n",
    "        epochs: Number of epochs to train\n",
    "        batch_size: Number of mini-sequences per mini-batch, aka batch size\n",
    "        lr: learning rate\n",
    "        print_every: Number of steps for printing training and validation loss\n",
    "    \n",
    "    '''\n",
    "    valid_batch = 1\n",
    "    net.train()\n",
    "    \n",
    "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    if(use_cuda):\n",
    "        net.cuda()\n",
    "    all_valid_losses = [.6]\n",
    "    counter = 0\n",
    "    for e in range(epochs):\n",
    "        \n",
    "        for batch_idx, batch_data in enumerate(train_loader):\n",
    "            inputs = batch_data[0].view(12,batch_size,1024)\n",
    "            inputs = inputs[0:4]\n",
    "            targets = batch_data[1]\n",
    "            if(use_cuda):\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            # zero accumulated gradients\n",
    "            net.zero_grad()\n",
    "            # get the output from the model\n",
    "            output = net(inputs)\n",
    "            # calculate the loss and perform backprop\n",
    "            loss = criterion(output.view(batch_size,2), targets)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            # loss stats\n",
    "            if batch_idx % print_every == 0:\n",
    "                # Get validation loss\n",
    "                val_losses = []\n",
    "                net.eval()\n",
    "                correct = 0.\n",
    "                total = 0.\n",
    "                for val_batch_idx, batch_data in enumerate(valid_loader):                    \n",
    "                    inputs, targets = batch_data[0].view(12,valid_batch,1024), batch_data[1]\n",
    "                    inputs = inputs[0:4]\n",
    "                    \n",
    "                    if(use_cuda):\n",
    "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "                    output = net(inputs)\n",
    "                    val_loss = criterion(output.view(valid_batch,2), targets)\n",
    "                    val_losses.append(val_loss.item())\n",
    "                    pred = output.max(0,keepdim=True)[1]\n",
    "                    # compare predictions to true label\n",
    "                    correct += np.sum(np.squeeze(pred.eq(targets.data.view_as(pred))).cpu().numpy())\n",
    "                    total += valid_batch\n",
    "                \n",
    "                net.train() # reset to train mode after iteration through validation data\n",
    "                \n",
    "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                      \"Step: {}...\".format(batch_idx),\n",
    "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
    "                      \"Val Loss: {:.4f}...\".format(np.mean(val_losses)),\n",
    "                      \"Val Accuracy: {:.1f}%\".format(correct/total*100))\n",
    "                \n",
    "                if np.mean(val_losses) < np.min(all_valid_losses):\n",
    "                    print(\"Validation loss dropped, saving model.\")\n",
    "                    torch.save(net,'DNNModel_' + saveName + '.pt')\n",
    "                    all_valid_losses = np.append(all_valid_losses,np.mean(val_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFARNet1(\n",
      "  (conv1): Conv2d(12, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define and print the net\n",
    "\n",
    "# net = MM_DNN()\n",
    "net = CIFARNet1()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[12, 1, 32, 32]' is invalid for input of size 36864",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-d56a7b859833>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-71-a80a60629f34>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, train_loader, epochs, batch_size, lr, print_every)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[12, 1, 32, 32]' is invalid for input of size 36864"
     ]
    }
   ],
   "source": [
    "train(net,train_loader,50,1,print_every=6000,lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html \n",
    "class CIFARNet1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CIFARNet1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(12, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = CIFARNet1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 1, 3, 32, 32])\n",
      "Epoch: 1/10... Step: 0... Loss: 0.4893... Val Loss: 0.6183... Val Accuracy: 64.7%\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n",
      "torch.Size([12, 1, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "batch_size=1\n",
    "lr=0.0001\n",
    "print_every=6000\n",
    "valid_batch = 1\n",
    "net.train()\n",
    "\n",
    "opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if(use_cuda):\n",
    "    net.cuda()\n",
    "all_valid_losses = [.6]\n",
    "counter = 0\n",
    "for e in range(epochs):\n",
    "\n",
    "    for batch_idx, batch_data in enumerate(train_loader):\n",
    "        print(batch_data[0][0].shape)\n",
    "        # inputs = batch_data[0][0].view(12,batch_size,3,32,32)\n",
    "        inputs = batch_data[0][0]\n",
    "        inputs = inputs[0:4]\n",
    "        # print(inputs.shape)\n",
    "        inputs = inputs.view(batch_size,12,32,32)\n",
    "        targets = batch_data[1]\n",
    "        if(use_cuda):\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        # zero accumulated gradients\n",
    "        net.zero_grad()\n",
    "        # get the output from the model\n",
    "        output = net(inputs)\n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output.view(batch_size,2), targets)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        # loss stats\n",
    "        if batch_idx % print_every == 0:\n",
    "            # Get validation loss\n",
    "            val_losses = []\n",
    "            net.eval()\n",
    "            correct = 0.\n",
    "            total = 0.\n",
    "            for val_batch_idx, batch_data in enumerate(valid_loader): \n",
    "                # inputs, targets = batch_data[0].view(12,valid_batch,1024), batch_data[1]\n",
    "                inputs, targets = batch_data[0][0], batch_data[1]\n",
    "                inputs = inputs[0:4]\n",
    "                inputs = inputs.view(batch_size,12,32,32)\n",
    "\n",
    "                if(use_cuda):\n",
    "                    inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "                output = net(inputs)\n",
    "                # print(output)\n",
    "                \n",
    "                val_loss = criterion(output.view(valid_batch,2), targets)\n",
    "                val_losses.append(val_loss.item())\n",
    "                pred = output[0].max(0,keepdim=True)[1]\n",
    "                # print(pred)\n",
    "                # sm = nn.Softmax(dim=1)\n",
    "                # sm_outputs = sm(output)\n",
    "                # print(sm_outputs)\n",
    "                # compare predictions to true label\n",
    "                correct += np.sum(np.squeeze(pred.eq(targets.data.view_as(pred))).cpu().numpy())\n",
    "                total += valid_batch\n",
    "\n",
    "            net.train() # reset to train mode after iteration through validation data\n",
    "\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(batch_idx),\n",
    "                  \"Loss: {:.4f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.4f}...\".format(np.mean(val_losses)),\n",
    "                  \"Val Accuracy: {:.1f}%\".format(correct/total*100))\n",
    "\n",
    "            if np.mean(val_losses) < np.min(all_valid_losses):\n",
    "                print(\"Validation loss dropped, saving model.\")\n",
    "                torch.save(net,'DNNModel_' + saveName + '.pt')\n",
    "                all_valid_losses = np.append(all_valid_losses,np.mean(val_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.load('DNNModel_' + saveName + '.pt')\n",
    "stateDictName ='DNN_StateDict_' + saveName + '.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), stateDictName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load(stateDictName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load('DNN_StateDict_S3_Iter_1.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zip up state dict, get over to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below lines are only needed if allowing SageMaker to perform inference on the model.\n",
    "# I can walk you through that when you get there.\n",
    "\n",
    "#tarName = 'DNNModel_' + saveName + '.tar.gz' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#os.system('tar -cvzf ' + tarName + ' ' + stateDictName)\n",
    "#os.system('aws s3 cp ' + tarName + ' s3://ypb-ml-images/' + tarName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_derm-ai)",
   "language": "python",
   "name": "conda_derm-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
